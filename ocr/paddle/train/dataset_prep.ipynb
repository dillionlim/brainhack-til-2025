{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6165a01f-a084-49c8-b8b9-dc408334635a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.13.3)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (5.4.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (4.13.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (11.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 lxml\n",
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816dd0f-d86f-484c-ad07-d9b48f095c97",
   "metadata": {},
   "source": [
    "## Generating lines dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab91dfb-2d18-48eb-84d8-1dd05e1409f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "DATA_DIR = os.path.join(os.path.expanduser('~'), 'advanced/ocr')\n",
    "OUTPUT_DIR = os.path.join(os.path.expanduser('~'), 'datasets/ocr_lines/train_data/rec')\n",
    "\n",
    "\n",
    "def parse_hocr_lines(hocr_path):\n",
    "    with open(hocr_path, 'r', encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f, 'lxml-xml')\n",
    "\n",
    "    line_data = []\n",
    "\n",
    "    # Loop through all lines\n",
    "    for line in soup.find_all(id=re.compile(r'^line')):\n",
    "        title = line.get('title', '')\n",
    "        text = line.get_text(separator=' ', strip=True)\n",
    "\n",
    "        # Extract bounding box using regex\n",
    "        bbox_match = re.search(r'bbox (\\d+) (\\d+) (\\d+) (\\d+)', title)\n",
    "        if bbox_match:\n",
    "            x1, y1, x2, y2 = map(int, bbox_match.groups())\n",
    "            bbox = [x1, y1, x2, y2]\n",
    "            line_data.append({'text': text, 'bbox': bbox})\n",
    "\n",
    "    return line_data\n",
    "\n",
    "\n",
    "def handle_sample(num, use):\n",
    "    text_file_lines = []\n",
    "    \n",
    "    sample_name = f\"sample_{num}\"\n",
    "    \n",
    "    hocr_path = os.path.join(DATA_DIR, f\"{sample_name}.hocr\")\n",
    "    lines = parse_hocr_lines(hocr_path)\n",
    "    \n",
    "    image_path = os.path.join(DATA_DIR, f\"{sample_name}.jpg\")\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    sub_output_dir = os.path.join(OUTPUT_DIR, use)\n",
    "    os.makedirs(sub_output_dir, exist_ok=True)\n",
    "    \n",
    "    for idx, line in enumerate(lines):\n",
    "        bbox = line['bbox']\n",
    "        cropped_image = image.crop(bbox)\n",
    "        \n",
    "        img_file_name = f\"{sample_name}_line_{idx}.jpg\"\n",
    "        \n",
    "        output_path = os.path.join(sub_output_dir, img_file_name)\n",
    "        \n",
    "        cropped_image.save(output_path)\n",
    "        text_file_lines.append(\n",
    "            os.path.join(use, img_file_name) + \"\\t\" + line['text']\n",
    "        )\n",
    "        \n",
    "    return text_file_lines\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf8f37d-36dd-43c0-8525-8cc0af1b8e25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "len(os.listdir(DATA_DIR))//3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9da0894f-93c0-4f43-b019-44b644d28bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [20:03<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:33<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "label_lines_train = []\n",
    "for i in tqdm(range(500, 4500)):\n",
    "    label_lines_train.extend(handle_sample(i, 'train'))\n",
    "\n",
    "# Save to JSON or print\n",
    "txt_file = os.path.join(OUTPUT_DIR, \"rec_gt_train.txt\")\n",
    "with open(txt_file, 'w', encoding='utf-8') as f:\n",
    "    for line in label_lines_train:\n",
    "        f.write(line + '\\n')\n",
    "print(len(label_lines_train))        \n",
    "        \n",
    "label_lines_val = []\n",
    "for i in tqdm(range(500)):\n",
    "    label_lines_val.extend(handle_sample(i, 'test'))\n",
    "\n",
    "# Save to JSON or print\n",
    "txt_file = os.path.join(OUTPUT_DIR, \"rec_gt_test.txt\")\n",
    "with open(txt_file, 'w', encoding='utf-8') as f:\n",
    "    for line in label_lines_val:\n",
    "        f.write(line + '\\n')\n",
    "print(len(label_lines_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a70e498d-6165-4830-be34-af931002b6a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list = [len(t.split('\\t')[1]) for t in label_lines_val]\n",
    "max(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66d60e24-1cbf-4951-95b4-cff4cce381a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Image.open(os.path.join(OUTPUT_DIR, 'train', 'sample_1002_line_2.jpg')).save('check.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6870ac02-cb7a-488a-a9bc-d777b126d4aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252686"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_dir = os.path.join('./dataset/train_data/rec')\n",
    "with open(os.path.join(txt_dir, 'rec_gt_train.txt'), 'r') as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "    \n",
    "with open(os.path.join(txt_dir, 'rec_gt_test.txt'), 'r') as file:\n",
    "    lines.extend([line.rstrip() for line in file])\n",
    "    \n",
    "lines = [line.strip('-') for line in lines]\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f5f9956-5f8a-45f4-a961-2f0514d2342e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246887 5799\n"
     ]
    }
   ],
   "source": [
    "train, test = [], []\n",
    "for line in lines:\n",
    "    if 4000 <= int(line.split('\\t')[0].split('_')[1]) < 4100:\n",
    "        test.append(line)\n",
    "    else: \n",
    "        train.append(line)\n",
    "        \n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab63406f-1ad3-4400-9ef3-22c595ba9d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(train)\n",
    "random.shuffle(test)\n",
    "\n",
    "with open(os.path.join(txt_dir, \"train_small.txt\"), \"w\") as f:\n",
    "    for line in train:\n",
    "        f.write(line + \"\\n\")\n",
    "        \n",
    "with open(os.path.join(txt_dir, \"test_small.txt\"), \"w\") as f:\n",
    "    for line in test:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc2877b-20dc-4e7e-b0f7-d080a98ab2a2",
   "metadata": {},
   "source": [
    "## Generating Detections Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce5a9e1-88ee-4aa3-872b-aa57a2551c40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [08:48<00:00,  7.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:06<00:00,  7.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "DATA_DIR = os.path.join(os.path.expanduser('~'), 'advanced/ocr')\n",
    "OUTPUT_DIR = os.path.join('./dataset', 'det')\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)    \n",
    "\n",
    "\n",
    "def parse_hocr_lines(hocr_path):\n",
    "    with open(hocr_path, 'r', encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f, 'lxml-xml')\n",
    "\n",
    "    line_data = []\n",
    "\n",
    "    # Loop through all lines\n",
    "    for line in soup.find_all(id=re.compile(r'^line')):\n",
    "        title = line.get('title', '')\n",
    "        text = line.get_text(separator=' ', strip=True)\n",
    "\n",
    "        # Extract bounding box using regex\n",
    "        bbox_match = re.search(r'bbox (\\d+) (\\d+) (\\d+) (\\d+)', title)\n",
    "        if bbox_match:\n",
    "            x1, y1, x2, y2 = map(int, bbox_match.groups())\n",
    "            bbox = [[x1, y1], [x2, y1], [x2, y2], [x1, y2]]\n",
    "            line_data.append({'transcription': text, 'points': bbox})\n",
    "\n",
    "    return line_data\n",
    "\n",
    "\n",
    "def handle_sample(num):\n",
    "    text_file_lines = []\n",
    "    \n",
    "    sample_name = f\"sample_{num}\"\n",
    "    \n",
    "    hocr_path = os.path.join(DATA_DIR, f\"{sample_name}.hocr\")\n",
    "    lines = parse_hocr_lines(hocr_path)\n",
    "    \n",
    "    img_name = f\"{sample_name}.jpg\"\n",
    "        \n",
    "    text_file_lines.append(\n",
    "        img_name + \"\\t\" + json.dumps(lines)\n",
    "    )\n",
    "        \n",
    "    return text_file_lines\n",
    "\n",
    "\n",
    "# TRAIN\n",
    "anno_train = []\n",
    "for i in tqdm(range(500, 4500)):\n",
    "    anno_train.extend(handle_sample(i))\n",
    "\n",
    "# Save to JSON or print\n",
    "txt_file = os.path.join(OUTPUT_DIR, \"det_gt_train.txt\")\n",
    "with open(txt_file, 'w', encoding='utf-8') as f:\n",
    "    for word in anno_train:\n",
    "        f.write(word + '\\n')\n",
    "print(len(anno_train))        \n",
    "        \n",
    "# VAL\n",
    "anno_val = []\n",
    "for i in tqdm(range(500)):\n",
    "    anno_val.extend(handle_sample(i))\n",
    "\n",
    "# Save to JSON or print\n",
    "txt_file = os.path.join(OUTPUT_DIR, \"det_gt_test.txt\")\n",
    "with open(txt_file, 'w', encoding='utf-8') as f:\n",
    "    for word in anno_val:\n",
    "        f.write(word + '\\n')\n",
    "print(len(anno_val))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
