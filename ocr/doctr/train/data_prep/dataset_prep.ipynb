{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9600d2e-119b-4c5e-b9d6-ad457cdc149d",
   "metadata": {},
   "source": [
    "## Notebook for docTR dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "538279d4-d8aa-4732-ad97-8df748382609",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.13.3)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (5.4.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (4.13.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (11.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 lxml\n",
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d02b1498-5763-4fca-8f4e-3d57a03ee7f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf ~/datasets/ocr_words/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3924ee-b9be-4dcc-9121-dff45b0daf4c",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8edf1fe5-0bf0-4a41-aee0-ac5f38eda1f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from random import choice, randint, shuffle, random\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "DATA_DIR = os.path.join(os.path.expanduser('~'), 'advanced/ocr')\n",
    "OUTPUT_DIR = os.path.join(os.path.expanduser('~'), 'datasets/ocr_words')\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0e07bf-97f6-43c6-b111-7c16cc460439",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae5027be-9611-4f4c-93c8-68d7d4ee8487",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    # Mask to remove ghost text\n",
    "    blurred = cv2.GaussianBlur(img, (3, 3), 0)\n",
    "    thresh, _ = cv2.threshold(blurred, 0, 255, cv2.THRESH_OTSU)\n",
    "    img[img>thresh] = 255\n",
    "\n",
    "    # Make it fLavourless \n",
    "    img = cv2.medianBlur(img, 3)\n",
    "    return img\n",
    "\n",
    "def preprocess_bytes(image_bytes: bytes) -> np.ndarray:\n",
    "    nparr = np.frombuffer(image_bytes, np.uint8)\n",
    "    img = cv2.imdecode(nparr, cv2.IMREAD_GRAYSCALE)\n",
    "    img = preprocess(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32352330-b5da-4445-bece-362aa2e56bfa",
   "metadata": {},
   "source": [
    "## Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a12213-32c6-4adb-8621-4be3016f7d5c",
   "metadata": {},
   "source": [
    "### Crop images from provided OCR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b74fcb8-683d-48d3-a2da-c499bb0d45ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_hocr_words(hocr_path):\n",
    "    with open(hocr_path, 'r', encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f, 'lxml-xml')\n",
    "\n",
    "    word_data = []\n",
    "\n",
    "    # Loop through all words\n",
    "    for word in soup.find_all(id=re.compile(r'^word')):\n",
    "        title = word.get('title', '')\n",
    "        text = word.get_text(separator=' ', strip=True)\n",
    "\n",
    "        # Extract bounding box using regex\n",
    "        bbox_match = re.search(r'bbox (\\d+) (\\d+) (\\d+) (\\d+)', title)\n",
    "        if bbox_match:\n",
    "            x1, y1, x2, y2 = map(int, bbox_match.groups())\n",
    "            bbox = [x1, y1, x2, y2]\n",
    "            word_data.append({'text': text, 'bbox': bbox})\n",
    "\n",
    "    return word_data\n",
    "\n",
    "\n",
    "def handle_sample(num, json_data, im_dir):\n",
    "    text_file_words = []\n",
    "    \n",
    "    sample_name = f\"sample_{num}\"\n",
    "    \n",
    "    hocr_path = os.path.join(DATA_DIR, f\"{sample_name}.hocr\")\n",
    "    words = parse_hocr_words(hocr_path)\n",
    "    \n",
    "    image_path = os.path.join(DATA_DIR, f\"{sample_name}.jpg\")\n",
    "    # image = Image.open(image_path)\n",
    "    \n",
    "    with open(image_path, 'rb') as f:\n",
    "        img_b = f.read()\n",
    "        \n",
    "    img_arr = preprocess_bytes(img_b)\n",
    "    image = Image.fromarray(img_arr, mode=\"L\")\n",
    "    \n",
    "    for idx, word in enumerate(words):\n",
    "        bbox = word['bbox']\n",
    "        cropped_image = image.crop(bbox)\n",
    "        \n",
    "        img_file_name = f\"{sample_name}_word_{idx}.jpg\"\n",
    "        \n",
    "        output_path = os.path.join(im_dir, img_file_name)\n",
    "        \n",
    "        cropped_image.save(output_path)\n",
    "        json_data[img_file_name] = word['text'] \n",
    "\n",
    "def prep_set(images_idxs, use):\n",
    "    set_dir = os.path.join(OUTPUT_DIR, use)\n",
    "    im_dir = os.path.join(set_dir, 'images')\n",
    "    os.makedirs(set_dir, exist_ok=True)\n",
    "    os.makedirs(im_dir, exist_ok=True)\n",
    "\n",
    "    json_data = {}\n",
    "    for i in tqdm(images_idxs):\n",
    "        handle_sample(i, json_data, im_dir)\n",
    "    \n",
    "    json_data_items = list(json_data.items())\n",
    "    shuffle(json_data_items)\n",
    "    json_data = dict(json_data_items)\n",
    "    with open(os.path.join(set_dir, 'labels_org.json'), 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_data, f, indent=4)\n",
    "        \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bddad4d1-96cf-4279-8539-e0589f51e120",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../../test/issues.json', 'r') as f:\n",
    "    blurry_ls = json.load(f)\n",
    "\n",
    "dataset = set(blurry_ls[:324]).union(set(range(4200, 4500)))\n",
    "datals = list(dataset)\n",
    "shuffle(datals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c31bdd11-c4f3-47f6-bcd8-b8ceefd6d1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[738, 4471, 4244, 771, 1007, 4434, 4402, 4363, 4460, 2870]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datals[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2f52854-d485-4680-8111-cd8fdcd82397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:41<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:43<00:00,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_labels = prep_set(datals[:500], 'train')\n",
    "print(len(train_labels))\n",
    "val_labels = prep_set(datals[500:], 'val')\n",
    "print(len(val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea9a82f-07ac-4e75-ba0f-91c4f62d635a",
   "metadata": {},
   "source": [
    "### Confirming Crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ef11c61-1c72-4f2f-a687-9ca419cd7156",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'swiftly,'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[\"sample_1007_word_273.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebc47a8e-4204-4791-91b7-998f1344a6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./check.jpg'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil \n",
    "\n",
    "fp = os.path.join(os.path.expanduser('~'), 'datasets/ocr_words/val/images/generated_1.jpg')\n",
    "\n",
    "shutil.copyfile(fp, './check.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bffdc522-236a-494c-822b-919b8e2e2970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open('../check.jpg').size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49770751-347a-44e9-97c8-71b69c2cb96e",
   "metadata": {},
   "source": [
    "### Dataset Generation (text generated by ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e34283ee-7301-4a4c-8ed2-d093a1f1679a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"Brainhack_OCR_GPT_data.txt\", 'r') as f:\n",
    "    data = f.read()\n",
    "    \n",
    "# Cleaning up some errors\n",
    "data = re.sub(r'(?<=[a-z])I', 'l', data)\n",
    "data = re.sub(r'(?<=[a-z])I', 'l', data)\n",
    "data = data.replace('0ASIS', 'OASIS')\n",
    "data = data.replace('Ieaming', 'learning')\n",
    "data = data.replace('0RBIT', 'ORBIT')\n",
    "data = data.replace('0rbit', 'Orbit')\n",
    "\n",
    "l_words = ['leaving', 'lone', 'logistics', 'long', 'landscape', 'location', \n",
    "           'late', 'layers', 'limitaions', 'level', 'latency', 'line', 'less']  \n",
    " \n",
    "for l_word in l_words:\n",
    "    data = data.replace('I' + l_word[1:], l_word)\n",
    "\n",
    "with open('cleaned.txt', 'w') as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2109790f-b8a5-49ab-b305-013d3824b290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_salt_and_pepper(arr, amount=0.05):\n",
    "    \"\"\"Adds salt & pepper noise to an image (expects 'L' or 'RGB' mode).\"\"\"\n",
    "    noisy = arr.copy()\n",
    "    num_pixels = arr.shape[0] * arr.shape[1]\n",
    "    num_salt = int(amount * num_pixels)\n",
    "    num_pepper = int(amount * num_pixels)\n",
    "\n",
    "    # Add salt\n",
    "    for _ in range(num_salt):\n",
    "        i = randint(0, arr.shape[0] - 1)\n",
    "        j = randint(0, arr.shape[1] - 1)\n",
    "        noisy[i, j] = 255  # White\n",
    "\n",
    "    # Add pepper\n",
    "    for _ in range(num_pepper):\n",
    "        i = randint(0, arr.shape[0] - 1)\n",
    "        j = randint(0, arr.shape[1] - 1)\n",
    "        noisy[i, j] = 0  # Black\n",
    "        \n",
    "    return noisy\n",
    "\n",
    "def lighten_words(arr, lighten_val=100):\n",
    "    \"\"\"\n",
    "    Replaces white pixels (255) in a grayscale image with a lighter value (e.g., 220).\n",
    "    \"\"\"\n",
    "    lightened = arr.copy()\n",
    "    lightened[lightened == 0] = lighten_val\n",
    "    return lightened\n",
    "\n",
    "def load_words(use):\n",
    "    with open(f\"cleaned_final_{use}.txt\", 'r') as f:\n",
    "        text = f.read()\n",
    "        \n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text_ls = text.split(' ')\n",
    "    print(f\"{len(text_ls)} words\")\n",
    "    return text_ls\n",
    "\n",
    "def load_fonts(folder, sizes):\n",
    "    fonts = []\n",
    "    for f in os.listdir('fonts'):\n",
    "        if not f.endswith('.ttf'):\n",
    "            continue\n",
    "        for size in sizes:\n",
    "            fonts.append(ImageFont.truetype(os.path.join('fonts', f), size=size))\n",
    "    \n",
    "    return fonts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91714c4-16c9-40bf-8853-8cedeb87e966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Output directory\n",
    "OUTPUT_DIR = os.path.join(os.path.expanduser('~'), 'datasets/ocr_words/')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load font\n",
    "sizes = [25, 30, 35]\n",
    "fonts = load_fonts('fonts', sizes)\n",
    "\n",
    "def generate_set(use, num):\n",
    "    use_dir = os.path.join(OUTPUT_DIR, use)\n",
    "    img_dir = os.path.join(use_dir, \"images\")\n",
    "    os.makedirs(img_dir, exist_ok = True)\n",
    "    \n",
    "    # Load words\n",
    "    words = load_words(use)\n",
    "    words_len = len(words)\n",
    "    words_dict = {}\n",
    "\n",
    "    for i in tqdm(range(num)):\n",
    "        word = words[i%words_len]\n",
    "        font = choice(fonts)\n",
    "\n",
    "        # Dummy image to get tight bounding box\n",
    "        dummy_img = Image.new(\"RGB\", (1, 1))\n",
    "        draw = ImageDraw.Draw(dummy_img)\n",
    "        bbox = draw.textbbox((0, 0), word, font=font)\n",
    "\n",
    "        # Tight size based on actual text pixels\n",
    "        text_width = bbox[2] - bbox[0]\n",
    "        text_height = bbox[3] - bbox[1]\n",
    "\n",
    "        # Small padding to avoid clipping\n",
    "        padding = 2\n",
    "        img_width = text_width + padding * 2\n",
    "        img_height = text_height + padding * 2\n",
    "\n",
    "        # Create base image\n",
    "        img = Image.new(\"L\", (img_width, img_height), color=255)  # 'L' mode = grayscale\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        draw.text((-bbox[0] + padding, -bbox[1] + padding), word, font=font, fill=0)\n",
    "\n",
    "        # Augmentations:\n",
    "        arr = np.array(img)\n",
    "\n",
    "        lighten_val = randint(0, 180)\n",
    "        blur_deg = randint(0, 4)/2\n",
    "        salt_pepper_amt = randint(0,6)/100\n",
    "\n",
    "        arr = lighten_words(arr, lighten_val)\n",
    "        arr = gaussian_filter(arr, sigma=blur_deg)\n",
    "        arr = add_salt_and_pepper(arr, salt_pepper_amt)\n",
    "        \n",
    "        if random() < 0.5:\n",
    "            arr = preprocess(arr)\n",
    "\n",
    "        fn = f\"generated_{i}.jpg\"\n",
    "        Image.fromarray(arr, mode='L').save(os.path.join(img_dir, fn))\n",
    "        words_dict[fn] = word\n",
    "\n",
    "    with open(os.path.join(use_dir, 'generated.json'), 'w') as f:\n",
    "        json.dump(words_dict, f, indent=2)\n",
    "    print(f\"GENERATED {num} images...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64a1edc9-bb12-4861-9af9-009dd8ef6cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5683 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200000/200000 [08:29<00:00, 392.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED 200000 images...\n"
     ]
    }
   ],
   "source": [
    "generate_set('train', 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf16c9a3-1cb8-40a0-8521-8dbd38b1e60e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40000/40000 [01:33<00:00, 427.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATED 40000 images...\n"
     ]
    }
   ],
   "source": [
    "generate_set('val', 40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e4f0a9-909d-4473-94b9-78f335a6d6e0",
   "metadata": {},
   "source": [
    "### Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c4d7c6b-dd76-47ba-b574-288110be93e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def shuffle_labels(use):\n",
    "    fp_org = os.path.join(OUTPUT_DIR, use, 'labels_org.json')\n",
    "    with open(fp_org, 'r') as f:\n",
    "        labels_org = json.load(f)\n",
    "        \n",
    "    fp_gen = os.path.join(OUTPUT_DIR, use, 'generated.json')\n",
    "    with open(fp_gen, 'r') as f:\n",
    "        labels_gen = json.load(f)\n",
    "    \n",
    "    labels_org_ls = list(labels_org.items())\n",
    "    labels_gen_ls = list(labels_gen.items())\n",
    "    labels_ls = labels_org_ls + labels_gen_ls\n",
    "    \n",
    "    shuffle(labels_ls)\n",
    "    labels = dict(labels_ls)\n",
    "    \n",
    "    with open(os.path.join(OUTPUT_DIR, use, 'labels.json'), 'w') as f:\n",
    "        json.dump(labels, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0757c12-9c8d-40e2-be83-bb11c67a48ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_labels('train')\n",
    "shuffle_labels('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f984b738-55f8-4346-8197-05e77fda781d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42233"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(os.path.join(OUTPUT_DIR, 'val', 'images')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f182b739-e59c-46de-86e1-59d3f18753a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for x in os.listdir(os.path.join(OUTPUT_DIR, 'train', 'images')):\n",
    "    if os.path.isdir(os.path.join(OUTPUT_DIR, 'train', 'images', x)):\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8888a68e-8419-45ad-8d0d-dd59cab64c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42233\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(OUTPUT_DIR, 'val', 'labels.json'), 'r') as f:\n",
    "    print(len(json.load(f)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0458bd-b756-400a-ab63-1100f080ec29",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "acdefa5d-ea04-4d0d-923b-35ff480aef99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "OUTPUT_DIR = os.path.join(os.path.expanduser('~'), 'datasets/ocr_detection')\n",
    "\n",
    "\n",
    "def get_word_polygons(num):\n",
    "    sample_name = f\"sample_{num}\"\n",
    "    \n",
    "    hocr_path = os.path.join(DATA_DIR, f\"{sample_name}.hocr\")\n",
    "    \n",
    "    with open(hocr_path, 'r', encoding='utf-8') as f:\n",
    "        soup = BeautifulSoup(f, 'lxml-xml')\n",
    "\n",
    "    word_data = []\n",
    "\n",
    "    # Loop through all lines\n",
    "    for word in soup.find_all(id=re.compile(r'^word')):\n",
    "        title = word.get('title', '')\n",
    "\n",
    "        # Extract bounding box using regex\n",
    "        bbox_match = re.search(r'bbox (\\d+) (\\d+) (\\d+) (\\d+)', title)\n",
    "        if bbox_match:\n",
    "            x1, y1, x2, y2 = map(int, bbox_match.groups())\n",
    "            bbox = [[x1, y1], [x2, y1], [x2, y2], [x1, y2]]\n",
    "            word_data.append(bbox)\n",
    "\n",
    "    return word_data\n",
    "\n",
    "\n",
    "def create_set(imgs, use):\n",
    "    set_dir = os.path.join(OUTPUT_DIR, use)\n",
    "    im_dir = os.path.join(set_dir, 'images')\n",
    "    os.makedirs(im_dir, exist_ok=True)\n",
    "    \n",
    "    labels = {}\n",
    "    \n",
    "    for i in tqdm(imgs):\n",
    "        polygons = get_word_polygons(i)\n",
    "        img_fn = f\"sample_{i}.jpg\"\n",
    "        img_fp = os.path.join(DATA_DIR, img_fn)\n",
    "        \n",
    "        with open(img_fp, 'rb') as f:\n",
    "            img_b = f.read()\n",
    "                    \n",
    "        nparr = preprocess_bytes(img_b)\n",
    "        \n",
    "        img_save_path = os.path.join(im_dir, img_fn)\n",
    "        \n",
    "#         for polygon in polygons:\n",
    "#             bbox = [polygon[0][0], polygon[0][1], polygon[2][0], polygon[2][1]]\n",
    "#             bbox = [int(n) for n in bbox]\n",
    "#             x1, y1, x2, y2 = bbox\n",
    "#             cv2.rectangle(nparr, (x1, y1), (x2, y2), (0, 255, 0), 2) \n",
    "        \n",
    "        img = Image.fromarray(nparr, mode='L')\n",
    "        img.save(img_save_path)\n",
    "        \n",
    "        with open(img_save_path, 'rb') as f:\n",
    "            new_b = f.read()\n",
    "        \n",
    "        sha256hash = hashlib.sha256(new_b).hexdigest()\n",
    "        \n",
    "        labels[img_fn] = {\n",
    "            'img_dimensions': img.size,\n",
    "            'img_hash': sha256hash,\n",
    "            'polygons': polygons\n",
    "        }\n",
    "            \n",
    "    labels_ls = list(labels.items())\n",
    "    shuffle(labels_ls)\n",
    "    labels = dict(labels_ls)\n",
    "    \n",
    "    with open(os.path.join(set_dir, 'labels.json'), 'w') as f:\n",
    "        json.dump(labels, f, indent=2)\n",
    "        \n",
    "    print(f\"Created {len(labels)} imgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb735a80-1892-454b-aa04-619258e4237c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [26:08<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4000 imgs\n"
     ]
    }
   ],
   "source": [
    "create_set(list(range(4000)), 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "09ee25a2-1b46-4f79-96da-c7f138108c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:44<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 500 imgs\n"
     ]
    }
   ],
   "source": [
    "create_set(list(range(4000, 4500)), 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "841ecec4-d3f7-49bc-b3af-6c02239dd1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images/sample_200.jpg'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"sample_200.jpg\"\n",
    "shutil.copyfile(os.path.join(OUTPUT_DIR, 'train', 'images', x), f\"images/{x}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
